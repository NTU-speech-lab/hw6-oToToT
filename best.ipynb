{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載資料\n",
    "# !gdown --id '14CqX3OfY9aUbhGp4OpdSHLvq2321fUB7' --output data.zip\n",
    "# 解壓縮\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 讀取 label.csv\n",
    "import pandas as pd\n",
    "# 讀取圖片\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# Loss function\n",
    "import torch.nn.functional as F\n",
    "# 讀取資料\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# 載入預訓練的模型\n",
    "import torchvision.models as models\n",
    "# 將資料轉換成符合預訓練模型的形式\n",
    "import torchvision.transforms as transforms\n",
    "# 顯示圖片\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實作一個繼承 torch.utils.data.Dataset 的 Class 來讀取圖片\n",
    "class Adverdataset(Dataset):\n",
    "    def __init__(self, root, label, transforms):\n",
    "        # 圖片所在的資料夾\n",
    "        self.root = root\n",
    "        # 由 main function 傳入的 label\n",
    "        self.label = torch.from_numpy(label).long()\n",
    "        # 由 Attacker 傳入的 transforms 將輸入的圖片轉換成符合預訓練模型的形式\n",
    "        self.transforms = transforms\n",
    "        # 圖片檔案名稱的 list\n",
    "        self.fnames = []\n",
    "\n",
    "        for i in range(200):\n",
    "            self.fnames.append(\"{:03d}\".format(i))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 利用路徑讀取圖片\n",
    "        img = Image.open(os.path.join(self.root, self.fnames[idx] + '.png'))\n",
    "        # 將輸入的圖片轉換成符合預訓練模型的形式\n",
    "        img = self.transforms(img)\n",
    "        # 圖片相對應的 label\n",
    "        label = self.label[idx]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 由於已知這次的資料總共有 200 張圖片 所以回傳 200\n",
    "        return 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attacker:\n",
    "    def __init__(self, img_dir, label):\n",
    "        self.model = models.vgg16(pretrained=True)\n",
    "        self.model.to(DEVICE)\n",
    "        self.model.eval()\n",
    "        self.resize_factor = 300\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]        \n",
    "        rnd = np.random.randint(224, self.resize_factor)\n",
    "        w_rem = self.resize_factor - rnd\n",
    "        pad_left = np.random.randint(0, w_rem)\n",
    "        pad_right = w_rem - pad_left\n",
    "        h_rem = self.resize_factor - rnd\n",
    "        pad_top = np.random.randint(0, h_rem)\n",
    "        pad_bottom = h_rem - pad_left\n",
    "        \n",
    "        basic_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224), interpolation=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.mean, self.std, inplace=False)\n",
    "        ])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomApply([\n",
    "                transforms.Resize(rnd),\n",
    "                transforms.Pad((pad_left, pad_top, pad_right, pad_bottom))\n",
    "            ], 0.5),\n",
    "            transforms.Resize((224, 224), interpolation=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.mean, self.std, inplace=False)\n",
    "        ])\n",
    "        # 利用 Adverdataset 這個 class 讀取資料\n",
    "        self.dataset = Adverdataset('./data/images', label, basic_transform)\n",
    "        \n",
    "        self.loader = torch.utils.data.DataLoader(\n",
    "                self.dataset,\n",
    "                batch_size = 1,\n",
    "                shuffle = False)\n",
    "\n",
    "    # DI-2-FGSM\n",
    "    def fgsm(self, epsilon, data, target):\n",
    "        transformed = self.transform(data.cpu()).to(DEVICE)\n",
    "        transformed = transformed.reshape((1, 3, 224, 224))\n",
    "        transformed.requires_grad = True\n",
    "        output = self.model(transformed)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        if pred.item() != target.item():\n",
    "            return data\n",
    "        loss = F.nll_loss(output, target)\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = transformed.grad.data / torch.mean(transformed.grad.abs(), (1, 2, 3), keepdim=True)\n",
    "        data += data_grad.reshape(3, 224, 224) * epsilon\n",
    "        return data\n",
    "    \n",
    "    def attack(self, epsilon):\n",
    "        adv_results = []\n",
    "        failed = 0\n",
    "        for (data, target) in self.dataset:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            target = target.reshape((1))\n",
    "            adv_data = data.clone().detach()\n",
    "            \n",
    "            for itr in range(4):\n",
    "                adv_data = self.fgsm(epsilon, adv_data, target)\n",
    "            adv_data = adv_data.reshape((1, 3, 224, 224))\n",
    "            output = self.model(adv_data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            if pred.item() == target.item():\n",
    "                failed += 1\n",
    "            adv_ex = adv_data * torch.tensor(self.std, device=DEVICE).view(3, 1, 1) + torch.tensor(self.mean, device=DEVICE).view(3, 1, 1)\n",
    "            adv_ex = adv_ex.squeeze().detach().cpu().numpy()\n",
    "            np.clip(adv_ex, 0, 1, out=adv_ex)\n",
    "            data_raw = data * torch.tensor(self.std, device=DEVICE).view(3, 1, 1) + torch.tensor(self.mean, device=DEVICE).view(3, 1, 1)\n",
    "            data_raw = data_raw.squeeze().detach().cpu().numpy()\n",
    "            adv_results.append( (target.item(), pred.item(), data_raw, adv_ex) )\n",
    "        final_acc = failed / len(self.loader)\n",
    "        print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, failed, len(self.loader), final_acc))\n",
    "        return adv_results, final_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.001\tTest Accuracy = 173 / 200 = 0.865\n",
      "L-inf = 0.08358348794281482\n",
      "\n",
      "Epsilon: 0.005\tTest Accuracy = 173 / 200 = 0.865\n",
      "L-inf = 0.452865931391716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 讀入圖片相對應的 label\n",
    "df = pd.read_csv(\"./data/labels.csv\")\n",
    "df = df.loc[:, 'TrueLabel'].to_numpy()\n",
    "label_name = pd.read_csv(\"./data/categories.csv\")\n",
    "label_name = label_name.loc[:, 'CategoryName'].to_numpy()\n",
    "# new 一個 Attacker class\n",
    "attacker = Attacker('./data/images', df)\n",
    "# 要嘗試的 epsilon\n",
    "epsilons = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1]\n",
    "\n",
    "accuracies, examples = [], []\n",
    "results = []\n",
    "\n",
    "# 進行攻擊 並存起正確率和攻擊成功的圖片\n",
    "for eps in epsilons:\n",
    "    res, acc = attacker.attack(eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(res[:5])\n",
    "    results.append(res)\n",
    "    L_inf = 0\n",
    "    for img in res:\n",
    "        L_inf += np.linalg.norm((img[2] - img[3]).reshape(224 * 224 * 3), ord=np.inf)\n",
    "    L_inf /= 200\n",
    "    L_inf *= 255\n",
    "    print(f'L-inf = {L_inf}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 顯示圖片\n",
    "cnt = 0\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(len(epsilons)):\n",
    "    try:\n",
    "        os.mkdir(f'results/{epsilons[i]}')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    for j, img in enumerate(results[i]):\n",
    "        img = img[3] * 255\n",
    "        img = img.astype('uint8')\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img = Image.fromarray(img, 'RGB')\n",
    "        img.save(f'results/{epsilons[i]}/%03d.png' % j)\n",
    "\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]) * 2,cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig, adv, orig_img, ex = examples[i][j]\n",
    "        # plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.title(\"original: {}\".format(label_name[orig].split(',')[0]))\n",
    "        orig_img = np.transpose(orig_img, (1, 2, 0))\n",
    "        plt.imshow(orig_img)\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]) * 2,cnt)\n",
    "        plt.title(\"adversarial: {}\".format(label_name[adv].split(',')[0]))\n",
    "        ex = np.transpose(ex, (1, 2, 0))\n",
    "        plt.imshow(ex)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
